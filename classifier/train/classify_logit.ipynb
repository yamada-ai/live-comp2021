{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from feature import Feature\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from tool.maneger import DataManager"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "path = \"../corpus/data_augment.csv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "data = []\n",
    "with open(path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data.append(row)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def make_classes_dict(data):\n",
    "    classes_dict = dict()\n",
    "    for row in data:\n",
    "        c = row[1]\n",
    "        if c not in classes_dict:\n",
    "            classes_dict[c] = len(classes_dict)\n",
    "    return classes_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def class_filter(data, remain_classes:list):\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        c = row[1]\n",
    "        if c in remain_classes:\n",
    "            new_data.append(row)\n",
    "    return new_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "classes_dict_ = make_classes_dict(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "remain_classes = \"how what when where who why YN plain\".split()\n",
    "data_n = class_filter(data, remain_classes)\n",
    "classes_dict = dict(zip(remain_classes, list(range(len(remain_classes)))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def extract_X_y(data, classes_dict):\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in data:\n",
    "        X.append(d[0])\n",
    "        y.append(classes_dict[d[1]])\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "import random\n",
    "def extract_X_y_limit(data, classes_dict:dict, limit=50):\n",
    "    data_ = random.sample(data, len(data))\n",
    "    X = []\n",
    "    y = []\n",
    "    each_len = dict(zip(classes_dict.keys(), [0]*len(classes_dict)))\n",
    "    for d in data_:\n",
    "        if each_len[d[1]] <= limit:\n",
    "            X.append(d[0])\n",
    "            y.append(classes_dict[d[1]])\n",
    "            each_len[d[1]] += 1\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# X, y = extract_X_y(data_n, classes_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "X, y = extract_X_y_limit(data_n, classes_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "len(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "F = Feature()\n",
    "F.make_features(X_train_str)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i, x_t_str in enumerate( X_train_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_train.append(x)\n",
    "for i, x_t_str in enumerate( X_test_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_test.append(x)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "F_path = \"../X_y_data/\"\n",
    "F_name = \"typeClassify_F2.dill\"\n",
    "import dill\n",
    "# featureM = DataManager(F_path, format_=\"dill\")\n",
    "with open(F_path+F_name, \"wb\") as f:\n",
    "    dill.dump(F, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "lr = LogisticRegression(solver='sag', max_iter=1000)\n",
    "lr.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='sag')"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "y_pred = lr.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "print(classes_dict)\n",
    "dis = 30\n",
    "for y_p, x_s in zip(y_pred[:dis], X_test_str[:dis]):\n",
    "    print(\"{0} : {1}\".format(y_p, x_s))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'how': 0, 'what': 1, 'when': 2, 'where': 3, 'who': 4, 'why': 5, 'YN': 6, 'plain': 7}\n",
      "1 : みなさん乗った？\n",
      "2 : 劇の稽古はいつ？\n",
      "1 : ぼくは何をすればいい？\n",
      "1 : 何だって？\n",
      "4 : これはだれのノートかな？\n",
      "5 : どうして君たちは仲良くできないんだい？\n",
      "7 : 実は、わたしは走ることがあまり好きではないんですよ。\n",
      "1 : 何で、ロボコーパスはいなくなったの？\n",
      "5 : ドン、あなたの弟にとって、あなたはあまり気を遣う必要がない人なのよ、そうは思わない？\n",
      "6 : 聞いてもいいですか？\n",
      "3 : マリーナ駅はどこですか？\n",
      "7 : 我々は年度末までに何を達成したいのか、考えてみましょう。\n",
      "7 : 学生時代に、日本で外国人旅行客のツアーガイドのアルバイトをしていた時、最もよく質問されたことの1つが、「向こうにいるあの人たちはなぜマスクをしているのですか。\n",
      "5 : とにかく、いつ帰ってくるの？\n",
      "5 : なぜ、「commencement」と呼ばれるんだろう？\n",
      "5 : 誰が、このお知らせを掲示板に載せたの？\n",
      "1 : 誰がそのおいしそうなチョコレートケーキを作ったの？\n",
      "2 : 提出期限はいつですか。\n",
      "7 : 私にはいろいろなことがわかります。\n",
      "5 : おばあさんに電話してあげたらどうなの？\n",
      "3 : 巻き戻しボタンはどこかしら？\n",
      "2 : そのコンサートはいつあったの？\n",
      "0 : 「おお、ロミオ、ロミオ！　あなたはなぜロミオなの？」\n",
      "5 : なぜ…なぜもっと早くわたしに言わなかったの？\n",
      "3 : どこの出身なの？\n",
      "0 : 体調はどうですか？\n",
      "5 : ピンクベリー・キャンディーのほかのメンバーも誘ってもらえませんか？\n",
      "6 : ＣＤ売り場はありますか？\n",
      "1 : そのパーティーのことをどうやって知ったのですか。\n",
      "1 : どういう意味かな？\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[ 6  4  0  0  0  1  3  0]\n",
      " [ 0  6  0  0  3  0  0  1]\n",
      " [ 1  1 11  0  0  1  0  1]\n",
      " [ 0  0  0 16  2  0  1  0]\n",
      " [ 1  1  2  0 14  1  1  1]\n",
      " [ 1  1  0  0  0 11  0  0]\n",
      " [ 0  3  0  1  2  2  7  0]\n",
      " [ 0  1  0  0  0  1  0 14]]\n",
      "accuracy =  0.6910569105691057\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "model_path = \"../models/\"\n",
    "model_name = \"typeClassify_M2.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "typeClassify_M2.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "modelM.save_data(model_name, lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/typeClassify_M2.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}