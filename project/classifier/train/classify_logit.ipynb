{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import csv\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from feature import Feature\n",
    "import sys\n",
    "sys.dont_write_bytecode = True\n",
    "sys.path.append('../')\n",
    "from datatool.preprocess import  Preprocessor\n",
    "from datatool.maneger import DataManager"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path = \"../corpus/data_augment.csv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = []\n",
    "with open(path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        data.append(row)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def make_classes_dict(data):\n",
    "    classes_dict = dict()\n",
    "    for row in data:\n",
    "        c = row[1]\n",
    "        if c not in classes_dict:\n",
    "            classes_dict[c] = len(classes_dict)\n",
    "    return classes_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def class_filter(data, remain_classes:list):\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        c = row[1]\n",
    "        if c in remain_classes:\n",
    "            new_data.append(row)\n",
    "    return new_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "classes_dict_ = make_classes_dict(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "remain_classes = \"how what when where who why YN plain\".split()\n",
    "data_n = class_filter(data, remain_classes)\n",
    "classes_dict = dict(zip(remain_classes, list(range(len(remain_classes)))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def extract_X_y(data, classes_dict):\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in data:\n",
    "        X.append(d[0])\n",
    "        y.append(classes_dict[d[1]])\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import random\n",
    "def extract_X_y_limit(data, classes_dict:dict, limit=400):\n",
    "    data_ = random.sample(data, len(data))\n",
    "    X = []\n",
    "    y = []\n",
    "    each_len = dict(zip(classes_dict.keys(), [0]*len(classes_dict)))\n",
    "    for d in data_:\n",
    "        if each_len[d[1]] <= limit:\n",
    "            X.append(d[0])\n",
    "            y.append(classes_dict[d[1]])\n",
    "            each_len[d[1]] += 1\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# X, y = extract_X_y(data_n, classes_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X, y = extract_X_y_limit(data_n, classes_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "len(X)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3208"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_train_str, X_test_str, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "F = Feature()\n",
    "F.set_preprocessor(Preprocessor())\n",
    "F.make_features(X_train_str)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "for i, x_t_str in enumerate( X_train_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_train.append(x)\n",
    "for i, x_t_str in enumerate( X_test_str ):\n",
    "    x = F.featurization(x_t_str)\n",
    "    X_test.append(x)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "F_path = \"../X_y_data/\"\n",
    "F_name = \"typeClassify_F2.pickle\"\n",
    "import dill\n",
    "import pickle\n",
    "# featureM = DataManager(F_path, format_=\"dill\")\n",
    "with open(F_path+F_name, \"wb\") as f:\n",
    "    pickle.dump(F, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "lr = LogisticRegression(solver='sag', max_iter=100)\n",
    "lr.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/yamada/.local/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(solver='sag')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "y_pred = lr.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(classes_dict)\n",
    "dis = 30\n",
    "for y_p, x_s in zip(y_pred[:dis], X_test_str[:dis]):\n",
    "    print(\"{0} : {1}\".format(y_p, x_s))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'how': 0, 'what': 1, 'when': 2, 'where': 3, 'who': 4, 'why': 5, 'YN': 6, 'plain': 7}\n",
      "5 : どうして？\n",
      "2 : 夏のバイトはいつ終わるの？\n",
      "6 : 向こうで雨宿りしない？\n",
      "7 : 私はこのところボランティアの指導員として、地元の10代の若者たち数人が整理能力と時間管理能力を向上させる支援をしています。\n",
      "7 : 初めての現代的なオリンピックがギリシャで1896年に開かれたということを知っていましたか？\n",
      "2 : いつ見えなくなったの？\n",
      "1 : どういうことなの？\n",
      "6 : どうにか不自由なくなじんできましたか。\n",
      "0 : 台本の進み具合はどう？\n",
      "5 : ひと休みしませんか？\n",
      "2 : このお店はいつオープンしましたか？\n",
      "7 : ねえ、たいていの人は、「スロー」ということばを聞くと否定的な反応をしますよね。\n",
      "2 : クローディアが自分の財布を捜して遺失物取扱所に電話したとき、顧客係は「それはどんなものだったのか私に説明してもらえますか？」と尋ねました。\n",
      "4 : だれがこんなところに置いていったのかしら？\n",
      "6 : それはフィルム式のカメラ？\n",
      "4 : そこの城主はだれだったのですか？\n",
      "5 : 今夜、茶碗蒸しを作ったらどうかしら?\n",
      "5 : なぜそれらをもっと使わないのですか？\n",
      "2 : 智美の出る競技は、いつ始まるかな？\n",
      "1 : みんなは今何をしているの？\n",
      "2 : サッカーの練習はいつなの？\n",
      "5 : 小学校で体育を取らなかったの？\n",
      "5 : いったい全体、なんでイギリス人はバスルームやトイレにカーペットをしいているんだろう？\n",
      "7 : あなたのご同胞の皆さんに温かく迎え入れてもらい、感激しましたよ。\n",
      "5 : どうしておばあちゃんがここにいるんですか？\n",
      "6 : 買ったの？\n",
      "4 : これはだれの花束？\n",
      "3 : ぼくの番号はどこだろう？　…な、ないよ、ぼくの番号がないんだ。\n",
      "0 : 毎朝5時に起きるのですね。\n",
      "2 : ティノはいつ着いたの？\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print('confusion matrix = \\n', confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "print('accuracy = ', accuracy_score(y_true=y_test, y_pred=y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "confusion matrix = \n",
      " [[ 99   9   0   0   0   8   6   4]\n",
      " [ 11  91   0   1   2   8   8   4]\n",
      " [  2   0 127   0   0   0   4   0]\n",
      " [  2   2   1  97   0   1   3   0]\n",
      " [  1   1   0   0 116   1   2   1]\n",
      " [ 10   3   0   1   0  94   7   4]\n",
      " [  5   8   1   0   3   8  75   9]\n",
      " [  2   2   0   1   2   2   6 108]]\n",
      "accuracy =  0.838006230529595\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model_path = \"../models/\"\n",
    "model_name = \"typeClassify_M2.pickle\"\n",
    "modelM = DataManager(model_path)\n",
    "print(model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "typeClassify_M2.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "modelM.save_data(model_name, lr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success save : ../models/typeClassify_M2.pickle\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}